---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

#title: "Exploring Machine Learning: Predicting Income and Race"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: TRUE
Entry1: "Exploring Machine Learning: Predicting Income and Race"
Entry2: "Cassandra Pengelly | 20346212" # textbf for bold
Entry3: "Data Science 871: Machine Learning Project"
Uni_Logo: images/m.jpg # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
Logo_width: 0.5
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
#AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
#Author1: "Cassandra Pengelly"  # First Author - note the thanks message displayed as an italic footnote of first page.
#Ref1: "Stellenbosch University" # First Author's Affiliation
#Email1: "20346212\\@sun.ac.za" # First Author's Email address

# Author2: "John Smith"
# Ref2: "Some other Institution, Cape Town, South Africa"
# Email2: "John\\@gmail.com"
# CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.

# Author3: "John Doe"
# Email3: "Joe\\@gmail.com"

#CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
#keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
#JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: TRUE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
# abstract: |
#   Abstract to be written here. The abstract should not be too long and should provide the reader with a good understanding what you are writing about. Academic papers are not like novels where you keep the reader in suspense. To be effective in getting others to read your paper, be as open and concise about your findings here as possible. Ideally, upon reading your abstract, the reader should feel he / she must read your paper in entirety.
---

<!-- Setting default preferences for chunk options and loading in libraries: -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')

if(!require("tidyverse")) install.packages("tidyverse") # This will install the pakages I used for the project if they are not already loaded on your computer
if(!require("caret")) install.packages("caret")
if(!require("ggplot2")) install.packages("ggplot2")
if(!require("e1071")) install.packages("e1071")
if(!require("haven")) install.packages("haven")
if(!require("glmnet")) install.packages("glmnet")
if(!require("rsample")) install.packages("rsample")

library(caret)
library(ggplot2)
library(tidyverse)
library(e1071)
library(haven)
library(glmnet)
library(rsample)
```

<!-- ############################## -->
<!-- # Writing starts here #
<!-- ############################## -->
\newpage

# Introduction \label{Introduction}

Labour economists have long been interested in the identifying the factors that influence a person's income. 

This paper investigates how well machine learning techniques can predict income and race. The focus is on machine learning and the code, rather than the economic interpretation of the model results.

This paper^[This assignment was written using the package by @Texevier] is structured as follows. First, the data set - NIDS - is discussed in section \ref{Data}; then the methodology is explained in section \ref{Meth}. Section \ref{ML} applies machine learning techniques to the NIDS data set, and comprises two subsections. The first subsection (\ref{income}) compares the effectiveness of linear regression and regularized regression on predicting people's incomes. The second subsection (\ref{race}) evaluated 5 classification algrithms - Linear Discriminant Analysis, Classification and Regression Trees, k-Nearest Neighbors, Support Vector Machines with a linear kernel and Random Forest - on their accuracy in predicting a person's race. 

# Data  \label{Data}
The data used for this assignment was sourced from Wave 5 of the National Income Dynamics Survey (NIDS) (@nids). The survey is a nationally representative household panel study, which started in 2008 with a group of over 28,000 individuals from 7,300 households. The same households are surveyed every 2 years for NIDS. The latest survey - wave 5 - was conducted in 2017. For wave 5, a total of 39,434 individuals were interviewed; 20,113 of which were part of the original study - wave 1 - and 2,016 were from a top-up sample. NIDS is funded by the Department of Planning, Monitoring and Evaluation and the survey is implemented by the Southern Africa Labour and Development Research Unit (SALDRU) at the University of Cape Town. The data set is comprehensive and covers topics relating to poverty, health, household composition, mortality, expenditure, income and employment. The NIDS data set is partitioned into different units of observations (e.g. adults, children, household etc.); for this assignment, data on adults was used. 

One weakness of the NIDS data set is that it suffers from the common problem that households at the higher end of the income distribution tend to be underrepresented. This could be explained by the fact that the rich refuse to fill out forms or they underreport their incomes. Because race and income are highly correlated in South Africa, this could also imply that white people are undersampled. To correct for the sample data not representing the population income/race distribution, some balancing techniques are applied in section \ref{race}.

# Methodology \label{Meth}
I first made use of SQLite ^[I found I struggle quite a bit using SQL but it has got easier with practice. I'm still not 100% comfortable with it so I used dplyr to manipulate the data for the machine learning section.] to investigate and visualise the data. I first ran the code in the R script called SQL. I opened a new connection and called it nids, and wrote the NIDS data, which included waves 2-5, into tables in the NIDS database. I used a few lines of code to check what tables were in nids and what their source was. Then I started to explore the NIDS wave 5 data, for example looking at the column names. I queried the data and selected 7 variables for analysis: date of birth, income, gender, marital status, race, years of schooling and tertiary qualification. I used date of birth to calculate the variable 'age'. 

I cleaned the data by renaming the variables to be reader-friendly and removed values that were nonsensical (e.g. negative years of schooling) by applying filters to the data. I wanted to see the proportion of the races so I first manipulated the data in the SQL script and then used the function 'show_query' to get the code for SQL. I copied this into the r chunk in the markdown file and then graphed the results using ggplot2. The code below shows some of this process and output:

```{r, echo=TRUE}
library(DBI)
nids <- DBI::dbConnect(RSQLite::SQLite(), "data/nids-db~output.sqlite")
```

```{sql, connection=nids, output.var = "mydataframe", echo=TRUE}
SELECT `race`, COUNT(*) AS `n`
FROM (SELECT `w5_a_dob_y`, `w5_a_gen` AS `gender`, `w5_a_popgrp` AS `race`, 
`w5_a_em1pay` AS `income`, `w5_a_mar` AS `married`, `w5_a_edschgrd` AS `school`, 
`w5_a_edter` AS `tertiary` FROM `wave5`) WHERE (`race` > 0.0 AND `race` < 5.0)
GROUP BY `race`
```

```{r, echo=FALSE,message=FALSE, warning=FALSE, fig.cap = "Race Proportion"}
library(ggplot2)
library(tidyverse)
library(kableExtra)

ggplot(mydataframe) +
    geom_col(aes(x = race, y = n,)) +
    xlab("Race") +
  ylab("People") +
  ggtitle("Race proportions")

names<- data.frame("Race" = c("1 = African", "2 = Coloured", "3 = Asian/Indian", "4 = White")) %>% tibble::as_tibble() 
kable(names)
```

The bar graph above shows that the majority of people sampled are African and the smallest proportion are Asian/Indian. In general the proportions appear to match the race distribution of South Africans. The histogram 
below reports the number of years of schooling. We can see that the majority of the sample has had 12 years of schooling. The data for this graph was also manipulated using the SQL script and then the SQL code was copied into the r chunk. 

```{sql, connection=nids, output.var = "df", echo=FALSE, fig.cap = "Years of schooling"}
SELECT *
FROM (SELECT *
FROM (SELECT 2021.0 - `w5_a_dob_y` AS `age`, `w5_a_gen` AS `gender`, 
`w5_a_popgrp` AS `race`, `w5_a_em1pay` AS `income`, 
`w5_a_mar` AS `married`, `w5_a_edschgrd` AS `school`, 
`w5_a_edter` AS `tertiary`FROM `wave5`)
WHERE (`race` > 0.0 AND `race` < 5.0))
WHERE (`school` > 0.0 AND `school` < 16.0)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(tidyverse)

    ggplot(df, aes(x=school, fill = school)) + geom_histogram() +
    xlab("Years of Schooling") +
  ylab("People") +
  ggtitle("Schooling Distribution")
```

Looking at the proportion of people who are married versus those that are not, we can clearly see that there are more people married than unmarried in this sample, as the bar graph below demonstrates.
```{sql, connection=nids, output.var = "df1", echo=FALSE}
SELECT `married`, COUNT(*) AS `n`
FROM (SELECT 2021.0 - `w5_a_dob_y` AS `age`, `w5_a_gen` AS `gender`, `w5_a_popgrp` AS `race`, `w5_a_em1pay` AS `income`, `w5_a_mar` AS `married`, `w5_a_edschgrd` AS `school`, `w5_a_edter` AS `tertiary`
FROM `wave5`)
WHERE (`married` < 3.0 AND `married` > 0.0)
GROUP BY `married`
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(tidyverse)
library(kableExtra)

ggplot(df1) +
    geom_col(aes(x = married, y = n,)) +
    xlab("Married") +
  ylab("People") +
  ggtitle("Married proportions")

names<- data.frame("Married" = c("1 = Married", "2 = Not married")) %>% tibble::as_tibble() 
kable(names)
```

If I had wanted to use more than one of the NIDS data sets, say wave 4 and 5, I could merge the two data sets using the SQL code below. I lightly cleaned both data sets beforehand and then used the union_all function to merge them.
```{sql, connection=nids, output.var = "df2", echo=TRUE}
SELECT 2021.0 - `w5_a_dob_y` AS `age`, `w5_a_gen` AS `gender`, 
`w5_a_popgrp` AS `race`, `w5_a_em1pay` AS `income`, 
`w5_a_mar` AS `married`, `w5_a_edschgrd` AS `school`, 
`w5_a_edter` AS `tertiary` FROM `wave5`
UNION ALL
SELECT 2021.0 - `w4_a_dob_y` AS `age`, `w4_a_gen` AS `gender`, 
`w4_a_popgrp` AS `race`, `w4_a_em1pay` AS `income`, 
`w4_a_mar` AS `married`, `w4_a_edschgrd` AS `school`, 
`w4_a_edter` AS `tertiary` FROM `wave4`
```
The table below provides a glimpse into the first 5 rows of the newly joined data set. I output a variable in the previous chunk as a dataframe and then displayed the dataframe in a table in the next r chunk. However, I could have used the function 'head' in the SQL script on the joined dataframe and the used the 'collect()' function to save the output to a global object and then displayed that object as a dataframe. 

```{r, echo=FALSE,message=FALSE, warning=FALSE}
library(kableExtra)
kable(head(df2, n=5))
```

After the initial data exploration I decided to focus on predicting income and race using machine learning techniques, which are presented in the following section. 

# Machine Learning \label{ML}

 <!-- Data import -->
```{r}
library(haven)
Adult <- read_dta("data/Adult_W5_Anon_V1.0.0.dta") # read in the NIDS data and name the data set Adult (which is the unit of observation)
#View(Adult) # Having a look at the data
#ls(Adult) 
```

##  Predicting Income \label{income}

Econometrics often makes use of regression analysis to model economic phenomena, test economic hypotheses and to forecast economic activity @econ [p.2]. A popular method in econometric regression modeling is that of Ordinary Least Squares; however, advances in machine learning have presented alternative/augmenting methods that may be (more) useful. One such augmenting method is K-fold cross validation, which evaluates the skill of machine learning models. As @kfold [p. 569] explain, in K-fold cross validation, a data set is randomly split into $k$ number of groups, of similar sizes. The first group is considered a validation set and the method is fitted to the other $k-1$ groups. 

Below, \ref{Regression} displays 3 different linear regressions of log of income using K-fold cross validation. For these regressions I built a function "linreg", which takes in a data frame, cleans and splits the data into a training (70% of the full data set) and a test set (30% of the full data set) and runs 3 different linear regressions, applying K-fold cross validation. The sample size for regressions amounts to 4258 observations, with the training and testing sets amounting to 2982 and 1276 respectively. The results of the regressions are then collected and stored in a list, which is returned by the function. I use k = 10, because empirically k=10 has been shown have test error rate estimates that have relatively low bias and variance (@k). I have also set seed in the function for reproducibility. 

Based on the Mincerian wage equation, Regression 1 (see \ref{Regression}) regresses log of income on age, years of schooling and a dummy variable for if a person has a tertiary qualification or not. Regression 2 includes a variable for age-squared and the categorical variable race. Regression 3 includes a variable each for gender and marriage. The signs of the coefficients of the three regressions look fairly standard^[This at least is a good indication that the data is fairly well cleaned and is usable for testing the machine learning techniques] and most of the coefficients are statistically significant at 1% and lower. For the variables whose coefficients are not statistically significant, labour market literature and economic theory suggest that they are important controls and should be included, which justifies their presence.

```{r, results = 'asis'}
if(!require(huxtable)) install.packages(huxtable)
library(huxtable)
library(ggplot2)

Title <- "Log-Income Regression Output"
Label <- "Regression"
source("code/linreg.R")
models<- linreg(Adult)
lm1 <- models[[1]] 
lm2 <- models[[2]]
lm3 <- models[[3]]
htab <-
huxreg("Reg 1" = lm1, "Reg 2" = lm2, "Reg 3" = lm3, 
       statistics = character(0),
                note = "%stars%.") %>%
  set_caption(Title) %>%
  set_label(Label)
font_size(htab) <- 12
htab #call the table
```

Typically, economists are interested in evaluating the performance of a model, which can be done by assessing how well the model predicts the outcome variable. A useful statistical metric for measuring the performance of a regression model is the Root Mean Squared Error (RMSE) (@rmse).The RMSE measures the average error performed by the model in predicting the outcome for an observation. The mathematical formula for the RMSE is given by $$RMSE = mean(\sqrt{(observeds - predicteds)^2)})$$ 
This implies lower the RMSE, the better the model performs.

Table \ref{Stats} reports the RMSES for both the training data and the test data. We can see that the RMSEs decreased from regression 1 to regression 3 for both the training and test data. This indicates that regression 3 is a better model than both regressions 1 and 2 (and that regression 2 has better predictive power than regression 1). The RMSEs for the regression based on the training data are lower than for the test data. However, the RMSEs are close enough between the two data sets for all 3 models that the out-of-sample performance is fair; it does not seem that any of the models have been overfitted to the training data.

```{r, results = 'asis'}
# observations and RMSEs for each model
library(xtable)
library(kableExtra)
source("code/linreg.R")
#str(lm1)
models<- linreg(Adult)
source("code/linreg_pred.R")
data1 <- linreg_pred(Adult) %>% tibble::as_tibble() 
r<- models[[4]]
#n<- models[[5]]
names<- data.frame("Regression" = c("Reg 1", "Reg 2", "Reg 3"))

data <- bind_cols(names, r, data1) %>% rename("RMSE Train" = x, "RMSE Test" = Reg) %>% tibble::as_tibble() 
table <- xtable(data, caption = "Regression RMSEs and Observations", label = "Stats")
print.xtable(table,
             # tabular.environment = "longtable",
             floating = TRUE,
             table.placement = 'H',
             include.rownames = FALSE,
             # scalebox = 0.3,
             comment = FALSE,
             caption.placement = 'top'
)
```
The table above shows that as more explanatory variables are added to the regression, it appears that the model improves in predictive power. However, it could actually be the case that the model is over fitting the data. One method of addressing this issue is to use regularized regression, which constrains the estimated coefficients. It does this by introducing a penalty parameter in the objective function such that the sum of the sum of squared errors and the penalty parameter is minimised. Two common penalty parameters include the ridge and lasso methods. 

To apply the ridge and lasso methods I created two functions: 'plot_ridge' and 'plot_lasso'. These functions use the 'glmnet' package to run the regressions and return a plot of the results, which are reported below. The tuning parameter here is given by $\lambda$. Initially, as $\lambda$ increases there is a decrease in the mean-squared error (MSE) for the lasso method, where the first dotted line indicates the lowest MSE. For the smaller values of lambda, this means that the lasso models has improved upon the OLS model - it is providing a better fit. In the ridge model, as $\lambda$ increases, the coefficient sizes are being reduced but the number of coefficients remains the same. In the lasso model, after the log of $\lambda$ increases to more than -3, the number of parameters starts to decrease. 

```{r, warning =  FALSE, include=FALSE, fig.align = 'center', fig.height = 3, fig.width = 6, dev = 'png'}
## plot the ridge and lasso models MSEs and parameter values
## I saved these graphs as ridge.png and lasso.png

list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
r <- plot_ridge(Adult)
l <- plot_lasso(Adult)
```

<center>

![Ridge]("images/ridge.png") 

</center>

<center>

![Lasso]("images/lasso.png")

</center>

```{r, echo = FALSE, include= FALSE, message=FALSE, warning =  FALSE, results = 'FALSE'}
# plot the bar graph for comparing all the RMSEs
# I saved the graph as RMSE.png
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
df <- comp_RMSE(Adult)
df$variable <- as.character(df$variable)
df <- df %>% mutate(variable = replace(variable, variable == "train.RMSE", "RMSE Train")) %>%
  mutate(variable = replace(variable, variable == "test.RMSE", "RMSE Test"))

source("code/linreg.R")
#str(lm1)
models<- linreg(Adult)
source("code/linreg_pred.R")
data1 <- linreg_pred(Adult) %>% tibble::as_tibble()
r<- models[[4]]
#n<- models[[5]]
names<- data.frame("name" = c("Reg 1", "Reg 2", "Reg 3"))

data <- bind_cols(names, r, data1) %>% rename("RMSE Train" = x, "RMSE Test" = Reg) %>% tibble::as_tibble()
dff <- data %>% tidyr::gather(variable, value, -name)
final <- bind_rows(df, dff)

  library(dplyr)
  library(gridExtra)
  library(grid)
  library(ggplot2)
  library(lattice)

  g <- ggplot(data=final, aes(x=name, y=value, fill=variable)) +
    geom_bar(stat="identity", position=position_dodge()) +
    scale_fill_hue(name="") +
    xlab("") + ylab("RMSE") +
    theme(text = element_text(size=12),
          axis.text.x = element_text(angle = 45, hjust = 1))

  plot <- grid.draw(grid.arrange(g, ncol=1, top="RMSE comparison"))
  
```

I then created a function 'comp_RMSE', which finds the $\lambda$ that minimises the RMSEs for the ridge and lasso models and records the minimised RMSEs. These models are then used to predict the log of income for the test data. The bar chart below displays the RMSEs for the ridge and lasso models and compares them to a base linear regression and the three regressions from \ref{Regression}. Here, I adjusted the code from @ridge tutorial.

The graphs again shows that the RMSEs are lower for the training data than for the test data for all the models.

<center>

![RMSE comparison]("images/RMSE.png")

</center>

While economists are interested in predicting wage based on variables such as race and education, it might be interesting to see if race can be predicted using income and other variables. The next section explores this idea by applying classification algorithms on the NIDS data set.

## Predicting Race \label{race}

```{r, warning =  FALSE, fig.align = 'center', fig.cap = "ML on unbalanced data", fig.height = 3, fig.width = 6, dev = 'png'}
# list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
# cleaned <- clean(Adult)
# unbal <-ML_Plot(cleaned) # running the machine learning algorithms on unbalanced data
# plot(unbal)
```


```{r Figure2, warning =  FALSE, fig.align = 'center', fig.cap = "ML on balanced data (undersampled) \\label{Figure2}", fig.height = 3, fig.width = 6, dev = 'png'}
### This balancing section was in a function but it kept breaking the document when I tried to knit so I unfortunately had to pull it out and put it here

# library(ROSE)
# library(tidyverse)
# library(dplyr)
# africa <- cleaned %>% filter(race == "African" | race == "White") # First splitting the dataset
# coloured <- cleaned %>% filter(race == "Coloured" | race == "White")
#   # balanced data set with under-sampling
#   balanced.under <- ovun.sample(race~., data=africa,
#                                 p=0.5, seed=1,
#                                 method="under")$data
# 
#   # Balancing white and coloured
#   balanced.under1 <- ovun.sample(race~., data=coloured,
#                                  p=0.5, seed=1,
#                                  method="under")$data
# 
#   colour <- balanced.under1 %>% filter(race == "Coloured")
#   asia <- cleaned %>% filter(race == "Asian/Indian")
# 
#   bal_under <- bind_rows(balanced.under, colour, asia)
#   bal1 <- bal_under %>% tibble::as_tibble()
# # #str(cleaned)
# # #str(bal1)
# # source("code/balance_both.R")
# # bal2 <- balance_both(Adult) %>% tibble::as_tibble()
# source("code/ML_Plot.R")
# balu <- ML_Plot(bal1) # running the machine learning algorithms on balanced (undersampled) data
# plot(balu)
```


```{r Figure3 , warning =  FALSE, fig.align = 'center', fig.cap = "ML on balanced data", fig.height = 3, fig.width = 6, dev = 'png'}
# list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
# source("code/clean.R")
# cleaned <- clean(Adult)
# 
# ### This balancing section was also in a function but it kept breaking the document when I tried to knit so I unfortunately had to pull it out and put it here
# 
# library(ROSE)
# library(tidyverse)
# library(dplyr)
# 
#   africa <- cleaned %>% filter(race == "African" | race == "White") # First splitting the dataset
#   coloured <- cleaned %>% filter(race == "Coloured" | race == "African")
#   asian <- cleaned %>% filter(race == "Asian/Indian" | race == "African")
# 
# # balanced data set with both-sampling
#   balanced.both <- ovun.sample(race~., data=africa,
#                                p=0.5, seed=1,
#                                method="both")$data
# 
#   white <- balanced.both %>% filter(race == "White")
# 
#   # Balancing African and coloured
#   balanced.both1 <- ovun.sample(race~., data=coloured,
#                                 p=0.5, seed=1,
#                                 method="both")$data
# 
# 
# 
#   colour <- balanced.both1 %>% filter(race == "Coloured")
# 
#   # Balancing African and Asian
#   balanced.both2 <- ovun.sample(race~., data=asian,
#                                 p=0.5, seed=1,
#                                 method="both")$data
# 
#   asia <- balanced.both2 %>% filter(race == "Asian/Indian")
# 
#   bal_both <- bind_rows(balanced.both1, white, asia)
# 
#   bal2 <-  bal_both %>% tibble::as_tibble()
#   source("code/ML_Plot.R")
#   balb <- ML_Plot(bal1) # running the machine learning algorithms on balanced (both sampled) data
#   plot(balb)
```
<center>

![Machine Learning applied to unbalanced data]("images/unbal.png") 

</center>

<center>

![Machine Learning applied to balanced (undersampled) data]("images/bal1.png") 

</center>

<center>

![Machine Learning applied to balanced data]("images/bal2.png")

</center>


The graph below displays the confusion matrix and the tables report the relevant statistics. 

![Random Forest Confusion Matrix]("images/cmrf.png")

<center>

![Random Forest Statistics]("images/statsrf.png")

</center>

```{r dpi=350, include = TRUE, warning =  FALSE, fig.align = 'center', fig.cap = "Confusion Matrix \\label{Figure3}", dev = 'png'}
# # I saved the output g1 as an image: cmsvm.png
# list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
# cleaned <- clean(Adult)
# predicted <- ML_Predict(cleaned) # prediction results
# g1 <-draw_confusion_matrix(predicted[[5]]) # visualising the confusion matrix for rf
```

```{r Figure5, warning =  FALSE, fig.align = 'center', fig.height = 4, fig.width = 6, dev = 'png'}
# random forest stats
# I saved the output g2 as an image: statsrf.png
# list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
# cleaned <- clean(Adult)
# predicted <- ML_Predict(cleaned) # prediction results
# g2 <- draw_confusion_stats(predicted[[5]]) # tabulating the statistics of random forest
```


# Conclusion




\newpage

# References {-}

<div id="refs"></div>


