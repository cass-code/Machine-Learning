---
title: "Data Manipulation"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!-- Loading in packages -->

```{r}
#install.packages("e1071")
#install.packages("caret")
install.packages("ROSE")
library(caret)
library(ggplot2)
library(tidyverse)
library(e1071)
library(ROSE)
```

 <!-- Data import -->
```{r}
library(haven)
Adult <- read_dta("data/nids-w5-v1.0.0-stata14/Adult_W5_Anon_V1.0.0.dta") # read in the NIDS data and name the data set Adult (which is the unit of observation)
#View(Adult) # Having a look at the data
#ls(Adult) 
```

<!-- Cleaning the data -->
```{r}
clean <- Adult %>% mutate(age = 2021 - w5_a_dob_y) %>% rename (gender = w5_a_gen, race = w5_a_popgrp, income = w5_a_em1pay, married = w5_a_evmar, school = w5_a_edschgrd, uni = w5_a_edter) %>% select(age, gender, race, income, married, school, uni) # The NIDS data set has many variables so just selecting the ones I want

clean$race <- as.numeric(clean$race)

cleaned <- clean %>% filter(race > 0, income >=0, gender >0, married >0, school >=0, uni >=0) %>% mutate(race = replace(race, race == 1, "African")) %>% mutate(race = replace(race, race == 2, "Coloured")) %>% mutate(race = replace(race, race == 3, "Asian/Indian")) %>% mutate(race = replace(race, race == 4, "White")) %>% mutate(race = replace(race, race == 5, "Other")) %>% filter(race == "African" |race == "Coloured" |race == "Asian/Indian" |race == "White") %>% drop_na() 
```

```{r}
# list types for each attribute
sapply(cleaned, class)
cleaned$income <- as.numeric(cleaned$income) # realised that income and gender should be numeric
cleaned$gender <- as.numeric(cleaned$gender)
cleaned$race <- as.factor(cleaned$race) # race needs to be a factor not a character
```

```{r}
# Balancing the data set
africa <- cleaned %>% filter(race == "African" | race == "White") # First splitting the dataset 
coloured <- cleaned %>% filter(race == "Coloured" | race == "White")

library(ROSE)

# table(hacide.train$cls)
# table(africa$race)
# 
# # balanced data set with both over and under sampling
# balanced1 <- ovun.sample(race~., data=africa,
#                                 N=nrow(africa), p=0.5, 
#                                 seed=1, method="both")$data

# Balancing white and african
table(balanced1$race)

# balanced data set with over-sampling
balanced.under <- ovun.sample(race~., data=africa, 
                                  p=0.5, seed=1, 
                                  method="under")$data

table(balanced.under$race)

table(balanced1$race)

# Blancing white and coloured
balanced.under1 <- ovun.sample(race~., data=coloured, 
                                  p=0.5, seed=1, 
                                  method="under")$data

table(balanced.under1$race)

colour <- balanced.under1 %>% filter(race == "Coloured")
asia <- cleaned %>% filter(race == "Asian/Indian")

more.balanced <- bind_rows(balanced.under, colour, asia) 
table(more.balanced$race)
```

 
```{r}
# create a list of 80% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(cleaned$race, p=0.80, list=FALSE)
# select 20% of the data for validation
validation <- cleaned[-validation_index,]
# use the remaining 80% of data to training and testing the models
cleaned <- cleaned[validation_index,]
```

```{r}

part <- createDataPartition(more.balanced$race, p=0.80, list=FALSE)
# select 20% of the data for validation
val <- more.balanced[-part,]
# use the remaining 80% of data to training and testing the models
more.balanced <- more.balanced[part,]
```

```{r}
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
g <- ML_Plot(cleaned)
g
```


```{r}
# We can get a quick idea of how many instances (rows) and how many attributes (columns) the data contains with the dim function.

# dimensions of dataset
dim(cleaned)
```


```{r}
# Looking at the first 10 rows of the data
head(cleaned, n=10)
```

```{r}
# list the levels for the class
levels(cleaned$race)
```
```{r}
# summarize the class distribution
percentage <- prop.table(table(cleaned$race)) * 100
cbind(freq=table(cleaned$race), percentage=percentage)
```

```{r}
summary(cleaned)
```

# Testing and Machine Learning bit

```{r}

# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
```

Letâ€™s evaluate 5 different algorithms:

Linear Discriminant Analysis (LDA)
Classification and Regression Trees (CART).
k-Nearest Neighbors (kNN).
Support Vector Machines (SVM) with a linear kernel.
Random Forest (RF)

```{r}

# linear algorithms
set.seed(7)
fit.lda <- train(race~., data=cleaned, method="lda", metric=metric, trControl=control)

# nonlinear algorithms

# CART
set.seed(7)
fit.cart <- train(race~., data=cleaned, method="rpart", metric=metric, trControl=control)

# kNN
set.seed(7)
fit.knn <- train(race~., data=cleaned, method="knn", metric=metric, trControl=control)

# advanced algorithms
# SVM
set.seed(7)
fit.svm <- train(race~., data=cleaned, method="svmRadial", metric=metric, trControl=control)
# Random Forest
set.seed(7)
fit.rf <- train(race~., data=cleaned, method="rf", metric=metric, trControl=control)
```
```{r}
# summarize accuracy of models
results <- resamples(list(lda=fit.lda, cart=fit.cart, knn=fit.knn, svm=fit.svm, rf=fit.rf))
#results <- resamples(list(lda=fit.lda, cart=fit.cart, knn=fit.knn))
summary(results)
```

```{r}
dotplot(results)
```

```{r}
print(fit.cart)
```

# Predict

```{r}
# estimate skill of LDA on the validation dataset
predictions <- predict(fit.cart, validation)
confusionMatrix(predictions, validation$race)
```

