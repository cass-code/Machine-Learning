View(cm_st)
View(ldacon)
cm_cl <-data.frame(cm$byClass)
View(cm_cl)
cm_cl_p <- tableGrob(cm_cl)
cm_st_p <-  tableGrob(cm_st)
cm <- ldacon
# extract the confusion matrix values as data.frame
cm_d <- as.data.frame(cm$table)
# confusion matrix statistics as data.frame
cm_st <-data.frame(cm$overall)
cm_cl$cm.byClass <- round(cm_cl$cm.byClass,2)
View(cm_st)
# confusion matrix byClass to look at sensitivity and specificity etc as data.frame
cm_cl <-data.frame(cm$byClass)
cm_cl$cm.byClass <- round(cm_cl$cm.byClass,2)
View(cm_cl)
# here we also have the rounded percentage values
cm_p <- as.data.frame(prop.table(cm$table))
cm_d$Perc <- round(cm_p$Freq*100,2)
library(ggplot2)     # to plot
library(gridExtra)   # to put more
library(grid)        # plot together
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile() +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = 'red', size = 4) +
theme_light() +
guides(fill=FALSE)
cm_cl_p <- tableGrob(cm_cl)
cm_st_p <-  tableGrob(cm_st)
# all together
grid.arrange(cm_d_p, cm_cl_p, cm_st_p,nrow = 1, ncol = 3,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# all together
grid.arrange(cm_d_p, cm_st_p,nrow, cm_cl_p = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# all together
grid.arrange(cm_d_p, cm_st_p,nrow, cm_cl_p = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# round the values
cm_st$cm.overall <- round(cm_st$cm.overall,2)
cm_cl <- round(cm_cl,2)
View(cm_cl)
View(cm_st)
# round the values
cm_st$cm.overall <- round(cm_st$cm.overall,2)
View(cm_st)
cm_cl_p <- tableGrob(cm_cl)
cm_st_p <-  tableGrob(cm_st)
View(cm_st_p)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
View(ldacon)
cm <- ldacon
View(cm)
print(cm)
View(cm_d)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 3, ncol = 3,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 3, ncol = 1,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# Generate color gradients. Palettes come from RColorBrewer.
greenPalette <- c("#F7FCF5","#E5F5E0","#C7E9C0","#A1D99B","#74C476","#41AB5D","#238B45","#006D2C","#00441B")
redPalette <- c("#FFF5F0","#FEE0D2","#FCBBA1","#FC9272","#FB6A4A","#EF3B2C","#CB181D","#A50F15","#67000D")
getColor <- function (greenOrRed = "green", amount = 0) {
if (amount == 0)
return("#FFFFFF")
palette <- greenPalette
if (greenOrRed == "red")
palette <- redPalette
colorRampPalette(palette)(100)[10 + ceiling(90 * amount / total)]
}
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile() +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = 'pink', size = 4) +
theme_light() +
guides(fill=FALSE)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile() +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = '#C7E9C0', size = 4) +
theme_dark() +
guides(fill=FALSE)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile(aes(scale_fill_distiller(palette = "YlGnBu", direction = 1))) +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = '#C7E9C0', size = 4) +
theme_light() +
guides(fill=FALSE)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile(aes(discrete_fill_distiller(palette = "YlGnBu", direction = 1))) +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = '#C7E9C0', size = 4) +
theme_light() +
guides(fill=FALSE)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile(aes(scale_colour_distiller(palette = "YlGnBu", direction = 1))) +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = '#C7E9C0', size = 4) +
theme_light() +
guides(fill=FALSE)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
cm_d_p + scale_colour_distiller(palette = "YlGnBu")
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile() +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = '#C7E9C0', size = 4) +
theme_light() +
guides(fill=FALSE)
cm_d_p + scale_colour_distiller(palette = "YlGnBu")
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
cm_d_p + scale_fill_distiller(palette = "YlGnBu")
cm_d_p + scale_fill_brewer(palette = "Pastel")
cm_d_p + scale_fill_brewer(palette = "Pastel1")
cm_d_p + scale_colour_brewer(palette = "Pastel1")
cm_d_p + scale_fill_distiller(palette = "YlGnBu")
cm_d_p + scale_fill_brewer(palette = "Pastel1")
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
cm_d_p + scale_colour_brewer(palette = "Pastel1")
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
cm_d_p + scale_fill_brewer(palette = "Set1")
cm_d_p + scale_fill_distiller(palette = "Set1")
cm_d_p + scale_fill_distiller(palette = "Pastel1")
cm_d_p + scale_fill_distiller(palette = "Pastel2")
cm_d_p + scale_fill_distiller(palette = "Set2")
cm_d_p + scale_fill_distiller(palette = "Paired")
cm_d_p + scale_fill_distiller(palette = "Sectral")
cm_d_p + scale_fill_distiller(palette = "Spectral")
cm_d_p + scale_fill_distiller(palette = "RdBu")
cm_d_p + scale_fill_distiller(palette = "RdBu", direction=-1)
cm_d_p + scale_fill_distiller(palette = "RdBu", direction= 1)
cm_d_p + scale_fill_distiller(palette = "RdGn", direction = 1)
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile() +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = 'white', size = 4) +
theme_light() +
guides(fill=FALSE)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
cm_d_p <- cm_d_p + scale_fill_distiller(palette = "RdGn", direction = 1)
cm_d_p <- cm_d_p + scale_fill_distiller(palette = "Gn", direction = 1)
cm_d_p <- cm_d_p + scale_fill_distiller(palette = "Greens", direction = 1)
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile() +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = 'white', size = 4) +
theme_light() +
guides(fill=FALSE)
cm_d_p <- cm_d_p + scale_fill_distiller(palette = "Greens", direction = 1)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
# plotting the matrix
cm_d_p <-  ggplot(data = cm_d, aes(x = Prediction , y =  Reference, fill = Freq))+
geom_tile() +
geom_text(aes(label = paste("",Freq,",",Perc,"%")), color = 'black', size = 4) +
theme_light() +
guides(fill=FALSE)
cm_d_p <- cm_d_p + scale_fill_distiller(palette = "Greens", direction = 1)
# all together
grid.arrange(cm_d_p, cm_st_p, cm_cl_p, nrow = 2, ncol = 2,
top=textGrob("Confusion Matrix and Statistics",gp=gpar(fontsize=25,font=1)))
source( "code/draw_confusion_matrix.R")
draw_confusion_matrix(ldacon)
clead(Adult)
clean(Adult)
library(caret)
library(tidyverse)
# create a list of 70% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(cleaned$race, p=0.70, list=FALSE)
# select 30% of the data for validation
validation <- cleaned[-validation_index,]
# use the remaining 70% of data to training and testing the models
cleaned <- cleaned[validation_index,]
# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
cleaned <- clean(Adult)
library(caret)
library(tidyverse)
# create a list of 70% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(cleaned$race, p=0.70, list=FALSE)
# select 30% of the data for validation
validation <- cleaned[-validation_index,]
# use the remaining 70% of data to training and testing the models
cleaned <- cleaned[validation_index,]
# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
# linear algorithms
set.seed(7)
fit.lda <- train(race~., data=cleaned, method="lda", metric=metric, trControl=control)
# CART
set.seed(7)
fit.cart <- train(race~., data=cleaned, method="rpart", metric=metric, trControl=control)
# kNN
set.seed(7)
fit.knn <- train(race~., data=cleaned, method="knn", metric=metric, trControl=control)
predictlda <- predict(fit.lda, validation)
ldacon <- confusionMatrix(predictlda, validation$race)
predictcart <- predict(fit.cart, validation)
cartcon <- confusionMatrix(predictcart, validation$race)
predictknn <- predict(fit.knn, validation)
knncon <- confusionMatrix(predictknn, validation$race)
predicted <- list(ldacon, cartcon, knncon)
View(predicted)
draw_confusion_matrix(predicted[[1]])
draw_confusion_matrix(predicted[[2]])
draw_confusion_matrix(predicted[[3]])
cleaned <- clean(Adult)
predicted <- ML_Predict(cleaned)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
source( "code/ML_results.R")
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
cleaned <- clean(Adult)
predicted <- ML_Predict(cleaned)
g<-draw_confusion_matrix(predicted[[3]])
cleaned <- clean(Adult)
predicted <- ML_Predict(cleaned)
g<-draw_confusion_matrix(predicted[[3]])
# arranging all the graphs
a <-  grid.arrange(cm_d_p, cm_st_p, nrow = 2, ncol = 1,
top=textGrob("",gp=gpar(fontsize=25,font=1)))
View(cleaned)
# create a list of 70% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(cleaned$race, p=0.70, list=FALSE)
library(caret)
library(tidyverse)
# create a list of 70% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(cleaned$race, p=0.70, list=FALSE)
# select 30% of the data for validation
validation <- cleaned[-validation_index,]
# use the remaining 70% of data to training and testing the models
cleaned <- cleaned[validation_index,]
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
if(!require("tidyverse")) install.packages("tidyverse") # This will install the pakages I used for the project if they are not already loaded on your computer
if(!require("caret")) install.packages("caret")
if(!require("ggplot2")) install.packages("ggplot2")
if(!require("e1071")) install.packages("e1071")
if(!require("haven")) install.packages("haven")
if(!require("glmnet")) install.packages("glmnet")
if(!require("rsample")) install.packages("rsample")
library(caret)
library(ggplot2)
library(tidyverse)
library(e1071)
library(haven)
library(glmnet)
library(rsample)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
ibrary(kableExtra)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
table <- xtable(RMSE_data(Adult), caption = "Model RMSEs", label = "RMSE")
library(xtable)
table <- xtable(RMSE_data(Adult), caption = "Model RMSEs", label = "RMSE")
table <- xtable(RMSE_data(Adult), caption = "Model RMSEs", label = "RMSE")
table <- xtable(RMSE_data(Adult), caption = "Model RMSEs", label = "RMSE")
table <- xtable(RMSE_data(Adult), caption = "Model RMSEs", label = "RMSE")
table <- xtable(RMSE_data(Adult), caption = "Model RMSEs", label = "RMSE")
# random forest stats
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
cleaned <- clean(Adult)
predicted <- ML_Predict(cleaned) #svm prediction results
g2 <- draw_confusion_stats(predicted[[5]]) # tabulating the statistics
# random forest stats
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
# random forest stats
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
cleaned <- clean(Adult)
predicted <- ML_Predict(cleaned) #svm prediction results
g2 <- draw_confusion_stats(predicted[[5]]) # tabulating the statistics
predicted <- ML_Predict(cleaned) #svm prediction results
g2 <- draw_confusion_stats(predicted[[5]]) # tabulating the statistics
# # I saved the output g1 as an image: cmsvm.png
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
g1 <-draw_confusion_matrix(predicted[[5]]) # visualising the confusion matrix for rf
Wave5 <- read_dta("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Data Science/Machine Learning/Machine-Learning/data/Adult_W5_Anon_V1.0.0.dta")
Wave4 <- read_dta("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Data Science/Machine Learning/Machine-Learning/data/Adult_W4_Anon_V2.0.0.dta")
Wave3 <- read_dta("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Data Science/Machine Learning/Machine-Learning/data/Adult_W3_Anon_V3.0.0.dta")
Wave2 <- read_dta("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Data Science/Machine Learning/Machine-Learning/data/Adult_W2_Anon_V4.0.0.dta")
# Read in NIDS data
#(I tried downloading this from Data first using R but it gave too many problems - I think it was the passwords and API but I spent too long troubleshooting and decided to download and read it in manually)
Wave5 <- read_dta("data/Adult_W5_Anon_V1.0.0.dta")
Wave4 <- read_dta("data/Adult_W4_Anon_V2.0.0.dta")
Wave3 <- read_dta("data/Adult_W3_Anon_V3.0.0.dta")
Wave2 <- read_dta("data/Adult_W2_Anon_V4.0.0.dta")
library(haven)
library(haven)
Adult <- read_dta("data/Adult_W5_Anon_V1.0.0.dta") # read in the NIDS data and name the data set Adult (which is the unit of observation)
# libraries used
library(dplyr)
library(dbplyr)
library(tidyverse)
library(RSQLite)
library(haven)
# Starting with SQL
nids <- DBI::dbConnect(RSQLite::SQLite(), "data/nids-db~output.sqlite") #opening a new connection
# Writing the data into tables in the NIDS database
dbWriteTable(nids, "Wave2", Wave2)
dbWriteTable(nids, "Wave3", Wave3)
#dbWriteTable(nids, "Wave4", Wave4, overwrite = TRUE) I accidentally added the wrong data for wave 4 and had to overwrite it
dbWriteTable(nids, "Wave4", Wave4)
dbWriteTable(nids, "Wave5", Wave5)
# checking what tables are in the nids database (surprise! it's all the tables I just wrote to the database)
dbListTables(nids)
src_dbi(nids) # checking the source
w5 <- tbl(nids, "wave5")
dim(w5) # looking at the dimensions shows that there are 1144 columns but because dplyr is lazy it doesn't count the number of rows
head(w5, n = 5) # looking at the first 5 entries
colnames(w5) # looking at the column names to help identify interesting variables
raceprop <- tbl(nids, "wave5") %>%
select (w5_a_dob_y, w5_a_gen, w5_a_popgrp, w5_a_em1pay, w5_a_mar, w5_a_edschgrd, w5_a_edter) %>%
rename (gender = w5_a_gen, race = w5_a_popgrp, income = w5_a_em1pay, married = w5_a_mar, school = w5_a_edschgrd,
tertiary = w5_a_edter) %>%
filter(race > 0 & race<5) %>%
group_by(race) %>% tally()
show_query(raceprop) # getting the SQL code for r chunk
school_dist <- tbl(nids, "wave5") %>% mutate(age = 2021 - w5_a_dob_y) %>%
select (age, w5_a_gen, w5_a_popgrp, w5_a_em1pay, w5_a_mar, w5_a_edschgrd, w5_a_edter) %>%
rename (gender = w5_a_gen, race = w5_a_popgrp, income = w5_a_em1pay, married = w5_a_mar, school = w5_a_edschgrd,
tertiary = w5_a_edter) %>%
filter(race > 0 & race<5) %>%  filter(school < 16 & school >=0 )
show_query(school_dist) # getting the SQL code for r chunk
# bar graph for comparing all the RMSEs
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
headjoin <- head(joined, n=5) # looking at the first 5 rows of the joined data set
headjoin <- head(joined, n=5) %>% collect() # looking at the first 5 rows of the joined data set
cleanw5 <- tbl(nids, "wave5") %>%
mutate(age = 2021 - w5_a_dob_y) %>%
rename (gender = w5_a_gen, race = w5_a_popgrp, income = w5_a_em1pay, married = w5_a_mar, school = w5_a_edschgrd, tertiary = w5_a_edter) %>%
select(age, gender, race, income, married, school, tertiary) # basic cleaning of wave 5
cleanw4 <- tbl(nids, "wave4") %>%
mutate(age = 2021 - w4_a_dob_y) %>%
rename (gender = w4_a_gen, race = w4_a_popgrp, income = w4_a_em1pay, married = w4_a_mar, school = w4_a_edschgrd, tertiary = w4_a_edter) %>%
select(age, gender, race, income, married, school, tertiary) # basic cleaning of wave 4
joined <- union_all(cleanw5, cleanw4) # joining the two data sets
headjoin <- head(joined, n=5) %>% collect() # looking at the first 5 rows of the joined data set
View(headjoin)
set.seed(123)
split <- initial_split(cleaned, prop = 0.7, strata = "income")
income_train <- training(split)
income_test <- testing(split)
# libraries
library(caret)
library(ggplot2)
library(tidyverse)
library(rsample)
library(glmnet)
# cleaning data
clean <- Adult %>% mutate(age = 2021 - w5_a_dob_y) %>%
rename (gender = w5_a_gen, race = w5_a_popgrp, income = w5_a_em1pay, married = w5_a_mar, school = w5_a_edschgrd, tertiary = w5_a_edter) %>%
select(age, gender, race, income, married, school, tertiary) # The NIDS data set has many variables so just selecting the ones I want
clean$race <- as.numeric(clean$race)
cleaned <- clean %>% filter(race > 0, income >0, gender >0, married >0, school >=0, tertiary >=0) %>%
mutate(race = replace(race, race == 1, "African")) %>% mutate(race = replace(race, race == 2, "Coloured")) %>%
mutate(race = replace(race, race == 3, "Asian/Indian")) %>% mutate(race = replace(race, race == 4, "White")) %>%
mutate(race = replace(race, race == 5, "Other")) %>%
filter(race == "African" |race == "Coloured" |race == "Asian/Indian" |race == "White") %>%
mutate(age2 = age * age) %>%
mutate(income = replace(income, income > 0, log(income))) %>%
mutate(gender = replace(gender, gender == 2, 0)) %>%
mutate(tertiary = replace(tertiary, tertiary == 2, 0)) %>%
mutate(married = replace(married, married >= 2, 0)) %>%
rename (male = gender) %>%
drop_na()
cleaned$income <- as.numeric(cleaned$income) # realised these should be numeric
cleaned$gender <- as.numeric(cleaned$male)
cleaned$married <- as.numeric(cleaned$married)
cleaned$school <- as.numeric(cleaned$school)
cleaned$tertiary <- as.numeric(cleaned$tertiary)
cleaned$race <- as.factor(cleaned$race)
set.seed(123)
split <- initial_split(cleaned, prop = 0.7, strata = "income")
income_train <- training(split)
income_test <- testing(split)
X <- model.matrix(income ~ age + age2 + male + race + married + school + tertiary, income_train)[,-1]
Y <- log(income_train$income)
X <- model.matrix(income ~ age + age2 + male + race + married + school + tertiary, income_train)[,-1]
Y <- (income_train$income)
# CV ridge regression
ridge <- cv.glmnet(
x = X,
y = Y,
alpha = 0)
p <- plot(ridge)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
if(!require("tidyverse")) install.packages("tidyverse") # This will install the pakages I used for the project if they are not already loaded on your computer
if(!require("caret")) install.packages("caret")
if(!require("ggplot2")) install.packages("ggplot2")
if(!require("e1071")) install.packages("e1071")
if(!require("haven")) install.packages("haven")
if(!require("glmnet")) install.packages("glmnet")
if(!require("rsample")) install.packages("rsample")
library(caret)
library(ggplot2)
library(tidyverse)
library(e1071)
library(haven)
library(glmnet)
library(rsample)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
r <- plot_ridge(Adult)
p <- plot(ridge)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
r <- plot_ridge(Adult)
Y <- (income_train$income)
# CV ridge regression
ridge <- cv.glmnet(
x = X,
y = Y,
alpha = 0)
p <- plot(ridge)
#r <- plot_ridge(Adult)
l <- plot_lasso(Adult)
# plot the ridge and lasso models MSEs and parameter values
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
#r <- plot_ridge(Adult)
l <- plot_lasso(Adult)
#list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
#r <- plot_ridge(Adult)
#l <- plot_lasso(Adult)
final <- RMSE_data(Adult)
source("code/comp_RMSE.R")
df <- comp_RMSE(Adult)
df$variable <- as.character(df$variable)
df <- df %>% mutate(variable = replace(variable, variable == "train.RMSE", "RMSE Train")) %>%
mutate(variable = replace(variable, variable == "test.RMSE", "RMSE Test"))
source("code/linreg.R")
#str(lm1)
models<- linreg(Adult)
source("code/linreg_pred.R")
data1 <- linreg_pred(Adult) %>% tibble::as_tibble()
r<- models[[4]]
#n<- models[[5]]
names<- data.frame("name" = c("Reg 1", "Reg 2", "Reg 3"))
data <- bind_cols(names, r, data1) %>% rename("RMSE Train" = x, "RMSE Test" = Reg) %>% tibble::as_tibble()
dff <- data %>% tidyr::gather(variable, value, -name)
final <- bind_rows(df, dff)
library(dplyr)
df1 <- comp_table(Adult)
data <- final %>% tibble::as_tibble() %>% tidyr::spread(key = name,value = value) %>% as.data.frame() %>% select(-variable)
df1 <- comp_table(Adult)
# bar graph for comparing all the RMSEs
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
df <- comp_RMSE(Adult)
df$variable <- as.character(df$variable)
df <- df %>% mutate(variable = replace(variable, variable == "train.RMSE", "RMSE Train")) %>%
mutate(variable = replace(variable, variable == "test.RMSE", "RMSE Test"))
source("code/linreg.R")
#str(lm1)
models<- linreg(Adult)
#str(lm1)
models<- linreg(Adult)
source("code/linreg_pred.R")
data1 <- linreg_pred(Adult) %>% tibble::as_tibble()
data1 <- linreg_pred(Adult) %>% tibble::as_tibble()
r<- models[[4]]
#n<- models[[5]]
names<- data.frame("name" = c("Reg 1", "Reg 2", "Reg 3"))
data <- bind_cols(names, r, data1) %>% rename("RMSE Train" = x, "RMSE Test" = Reg) %>% tibble::as_tibble()
#n<- models[[5]]
names<- data.frame("name" = c("Reg 1", "Reg 2", "Reg 3"))
data <- bind_cols(names, r, data1) %>% rename("RMSE Train" = x, "RMSE Test" = Reg) %>% tibble::as_tibble()
dff <- data %>% tidyr::gather(variable, value, -name)
final <- bind_rows(df, dff)
final <- bind_rows(df, dff)
library(dplyr)
library(gridExtra)
library(grid)
library(ggplot2)
library(lattice)
g <- ggplot(data=final, aes(x=name, y=value, fill=variable)) +
geom_bar(stat="identity", position=position_dodge()) +
scale_fill_hue(name="") +
xlab("") + ylab("RMSE") +
theme(text = element_text(size=12),
axis.text.x = element_text(angle = 45, hjust = 1))
plot <- grid.draw(grid.arrange(g, ncol=1, top="RMSE comparison"))
View(Adult)
